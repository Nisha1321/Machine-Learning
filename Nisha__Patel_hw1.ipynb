{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpqT6HKaXV7t"
      },
      "source": [
        "# CS 584 :: Data Mining :: George Mason University :: Fall 2025\n",
        "\n",
        "\n",
        "# Homework 1: KNN&PCA\n",
        "\n",
        "- **100 points [6% of your final grade]**\n",
        "- **Due Tuesday, Sep 28 by 11:59pm**\n",
        "\n",
        "- *Goals of this homework:* (1) implement the KNN algorithm for classifying handwritten digit images; (2) implement the PCA algorithm to reduce the feature dimension so that we can speed up the KNN algorithm and also improve the classification performance; (3) tune the hyperparameters of the KNN and PCA algorithms to produce classification result as good as possible.\n",
        "\n",
        "- *Submission instructions:* for this homework, you should submit your notebook file to **Canvas** (look for the homework 1 assignment there). Please name your submission **FirstName_Lastname_hw1.ipynb**, so for example, my submission would be something like **Ziwei_Zhu_hw1.ipynb**. Your notebook should be fully executed so that we can see all outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnMMy5vXXdh-"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qaADdrnXV7x"
      },
      "source": [
        "## Part 1: KNN (50 points)\n",
        "\n",
        "In this part, you need to implement your own KNN algorithm for classifying the digits (from 0 to 9) from the handwritten digit images (28 pixels * 28 pixels). The provided train.txt is the training data you will use for building your model. Each line in the file is one sample, whose first value is the ground-truth label, and the following 784 values are the pixels of the image. First of all, let's load the data by executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bm0I7D5XV7x",
        "outputId": "ec3fcfea-c00b-4e6f-ac91-a178f3bcf48c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "array of labels: shape (60000,)\n",
            "array of feature matrix: shape (60000, 784)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "data = np.loadtxt('/content/drive/MyDrive/Colab Notebooks/train.txt', delimiter=',')\n",
        "labels = data[:, 0].astype(int)\n",
        "features = data[:, 1:]\n",
        "print('array of labels: shape ' + str(np.shape(labels)))\n",
        "print('array of feature matrix: shape ' + str(np.shape(features)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTXvbE-rXV70"
      },
      "source": [
        "Now, we have the label variable to store the ground-truth labels (from 0 to 9) of all 60,000 samples, and matrix features to store the image pixels of these samples. Next, let's execute the following code to plot the first 4 samples to see how these images look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "Gbjjg29dXV70",
        "outputId": "ef21e115-b774-4bda-b88a-713743391593"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x5000 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 4, figsize=(10, 50))\n",
        "for i in range(4):\n",
        "    ax[i].imshow(features[i].reshape((28, 28)), cmap=plt.get_cmap('gray'))\n",
        "    ax[i].set_title('Label is %d' % labels[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADMB2BJ1XV70"
      },
      "source": [
        "Next, you need to **randomly** select 20% samples (sampling without replacement) from the data as the **validation set**, and generate the new **training set** by removing the selected validation samples from the original dataset. Write your code in the next cell.\n",
        "\n",
        "**Note: You are NOT allowed to directly call APIs from an existing Machine Learning library like sklearn. But you can use the python 'random' library or the random module from 'numpy'**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us0T2CrFXV70",
        "outputId": "aa8d4cba-7854-41ae-96cf-8f1e96425865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples : 60000\n",
            "Validation samples : 12000\n",
            "Training samples : 48000\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "n = features.shape[0]\n",
        "val_ratio = 0.20\n",
        "val_size = int(n * val_ratio)\n",
        "\n",
        "\n",
        "val_idx = np.random.choice(n, size= val_size , replace=False)\n",
        "\n",
        "\n",
        "train_idx = [i for i in range(n) if i not in val_idx]\n",
        "\n",
        "X_train = features[train_idx]\n",
        "y_train = labels[train_idx]\n",
        "X_test   = features[val_idx]\n",
        "y_test   = labels[val_idx]\n",
        "\n",
        "\n",
        "\n",
        "print(\"Total samples :\",n)\n",
        "print(\"Validation samples :\",X_test.shape[0])\n",
        "print(\"Training samples :\",X_train.shape[0])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7PEB9VVXV71"
      },
      "source": [
        "Now, it's time to implement your KNN algorithm. In the next cell, please write your code to predict labels for samples in the validation set by the KNN model built on the training set. Here we set K = 10 and use the Euclidean distance to find neighbors.\n",
        "\n",
        "**Note: You should implement the algorithm by Python, Numpy, and other libraries you think are necessary. You are NOT allowed to directly call APIs from an existing Machine Learning library like sklearn.**\n",
        "\n",
        "**Note: Here, you should only use the labels from the training set for the KNN model.**\n",
        "\n",
        "**Note: You can install and use the 'tqdm' library to help you track the process of your algorithm. Details are 'https://github.com/tqdm/tqdm'**\n",
        "\n",
        "**Note: It takes 30~60 min to execute the KNN algorithm.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_d0fvbpXV71",
        "outputId": "f9e91f4d-a9dd-40c5-a8b8-372482d6b058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing sample 0/12000 ...\n",
            "Processing sample 500/12000 ...\n",
            "Processing sample 1000/12000 ...\n",
            "Processing sample 1500/12000 ...\n",
            "Processing sample 2000/12000 ...\n",
            "Processing sample 2500/12000 ...\n",
            "Processing sample 3000/12000 ...\n",
            "Processing sample 3500/12000 ...\n",
            "Processing sample 4000/12000 ...\n",
            "Processing sample 4500/12000 ...\n",
            "Processing sample 5000/12000 ...\n",
            "Processing sample 5500/12000 ...\n",
            "Processing sample 6000/12000 ...\n",
            "Processing sample 6500/12000 ...\n",
            "Processing sample 7000/12000 ...\n",
            "Processing sample 7500/12000 ...\n",
            "Processing sample 8000/12000 ...\n",
            "Processing sample 8500/12000 ...\n",
            "Processing sample 9000/12000 ...\n",
            "Processing sample 9500/12000 ...\n",
            "Processing sample 10000/12000 ...\n",
            "Processing sample 10500/12000 ...\n",
            "Processing sample 11000/12000 ...\n",
            "Processing sample 11500/12000 ...\n",
            "accuracy: 0.9664166666666667\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "K = 10\n",
        "\n",
        "y_train = np.asarray(y_train)\n",
        "y_test  = np.asarray(y_test)\n",
        "\n",
        "def predict_one(x, X_train, y_train, k=K):\n",
        "\n",
        "    dists = np.sqrt(np.sum((X_train - x) ** 2, axis=1))\n",
        "    k = min(k, len(X_train))\n",
        "    nn_indices = np.argsort(dists)[:k]\n",
        "    nn_labels = y_train[nn_indices]\n",
        "    values, counts = np.unique(nn_labels, return_counts=True)\n",
        "\n",
        "    pred_label = values[np.argmax(counts)]\n",
        "    return pred_label\n",
        "\n",
        "y_pred_val = np.empty_like(y_test)\n",
        "\n",
        "for i, x in enumerate(X_test):\n",
        "\n",
        "    if (i % 500) == 0:\n",
        "        print(f\"Processing sample {i}/{len(X_test)} ...\")\n",
        "    y_pred_val[i] = predict_one(x, X_train, y_train, k=K)\n",
        "\n",
        "acc = np.mean(y_pred_val == y_test)\n",
        "print(\"accuracy:\", acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm-L9nVMXV71"
      },
      "source": [
        "Then, please write code to compute the **Accuracy**, and **Micro-averaged and Macro-averaged F1 scores** to evaluate the performance on the validation set.\n",
        "\n",
        "Print out these three metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKXfmAvEXV71",
        "outputId": "714e4873-6f6d-49b5-c594-749b79df8653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy   : 0.9664166666666667\n",
            "Micro-F1   : 0.9664166666666667\n",
            "Macro-F1   : 0.9663638957039387\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "\n",
        "    correct = 0\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] == y_pred[i]:\n",
        "            correct += 1\n",
        "    return correct / len(y_true)\n",
        "\n",
        "\n",
        "def micro_f1(y_true, y_pred):\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    classes = np.unique(y_true)\n",
        "\n",
        "    for c in classes:\n",
        "        for i in range(len(y_true)):\n",
        "            if y_true[i] == c and y_pred[i] == c:\n",
        "                tp += 1\n",
        "            elif y_true[i] != c and y_pred[i] == c:\n",
        "                fp += 1\n",
        "            elif y_true[i] == c and y_pred[i] != c:\n",
        "                fn += 1\n",
        "\n",
        "    if tp + fp == 0:\n",
        "        precision = 0\n",
        "    else:\n",
        "        precision = tp / (tp + fp)\n",
        "\n",
        "    if tp + fn == 0:\n",
        "        recall = 0\n",
        "    else:\n",
        "        recall = tp / (tp + fn)\n",
        "\n",
        "    if precision + recall == 0:\n",
        "        return 0\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "\n",
        "def macro_f1(y_true, y_pred):\n",
        "    classes = np.unique(y_true)\n",
        "    f1_scores = []\n",
        "\n",
        "    for c in classes:\n",
        "        tp = fp = fn = 0\n",
        "        for i in range(len(y_true)):\n",
        "            if y_true[i] == c and y_pred[i] == c:\n",
        "                tp += 1\n",
        "            elif y_true[i] != c and y_pred[i] == c:\n",
        "                fp += 1\n",
        "            elif y_true[i] == c and y_pred[i] != c:\n",
        "                fn += 1\n",
        "\n",
        "        if tp + fp == 0:\n",
        "            precision = 0\n",
        "        else:\n",
        "            precision = tp / (tp + fp)\n",
        "\n",
        "        if tp + fn == 0:\n",
        "            recall = 0\n",
        "        else:\n",
        "            recall = tp / (tp + fn)\n",
        "\n",
        "        if precision + recall == 0:\n",
        "            f1 = 0\n",
        "        else:\n",
        "            f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    return sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Accuracy   :\", accuracy(y_test, y_pred_val))\n",
        "print(\"Micro-F1   :\", micro_f1(y_test, y_pred_val))\n",
        "print(\"Macro-F1   :\", macro_f1(y_test, y_pred_val))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDUxXIQbXV71"
      },
      "source": [
        "## Part 2: PCA (30 points)\n",
        "\n",
        "In this part, you will implement the PCA algorithm to reduce the input dimension for the handwritten digit recognition task. In the next cell, please write your code to compute the transformation matrix in the PCA method for the training set we got from the previous part. Here, we only keep the **top 50 dimensions**.\n",
        "\n",
        "**Hint: You can use the function from the Numpy library to compute SVD:**\n",
        "\n",
        "*u, s, v = np.linalg.svd(a, full_matrices=False)*\n",
        "\n",
        "\n",
        "**Note: You should only use the training set to compute PCA without using validation set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-tfy_ZmdXV72"
      },
      "outputs": [],
      "source": [
        "# your code is here\n",
        "import numpy as np\n",
        "\n",
        "top_k = 50\n",
        "train_mean = X_train.mean(axis=0)\n",
        "\n",
        "X_train_centered = X_train - train_mean\n",
        "U, S, Vt = np.linalg.svd(X_train_centered, full_matrices=False)\n",
        "W = Vt[:top_k, :]\n",
        "\n",
        "Z_train = (X_train - train_mean) @ W.T\n",
        "Z_val = (X_test - train_mean) @ W.T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kYjFYTXV72"
      },
      "source": [
        "Now, you need to apply the computed transformation matrix to reduce the dimension for the training set and the validation set. Then, build a new KNN model on the dimension-reduced training data and predict the labels for the dimension-reduced validation set.\n",
        "\n",
        "Print out the Accuracy, and Micro-averaged and Macro-averaged F1 scores.\n",
        "\n",
        "**Note: When you calculate the centered data for the validation set, you can calculate the mean feature values just by the validation data itself.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9VLv0rhXV72",
        "outputId": "af11d9ab-bf9a-4e45-c77f-a33a084b193a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy  (PCA-50, k=10): 0.9729\n",
            "Micro-F1  (PCA-50, k=10): 0.9729\n",
            "Macro-F1  (PCA-50, k=10): 0.9728\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "val_mean = X_test.mean(axis=0)\n",
        "Z_val = (X_test - train_mean) @ W.T\n",
        "\n",
        "\n",
        "\n",
        "K = 10\n",
        "\n",
        "def dist_l2(a, b):\n",
        "    diff = a - b\n",
        "    return float(np.dot(diff, diff)) ** 0.5\n",
        "\n",
        "def predict_one_knn(z, Ztr, ytr, k=K):\n",
        "    dists = [dist_l2(z, ztr) for ztr in Ztr]\n",
        "    nn = np.argsort(dists)[:k]\n",
        "    labs, cnt = np.unique(ytr[nn], return_counts=True)\n",
        "    return labs[np.argmax(cnt)]\n",
        "\n",
        "y_pred = np.array([predict_one_knn(z, Z_train, y_train, k=K) for z in Z_val])\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return sum(int(y_true[i] == y_pred[i]) for i in range(len(y_true))) / len(y_true)\n",
        "\n",
        "def micro_f1(y_true, y_pred):\n",
        "    tp = fp = fn = 0\n",
        "    classes = np.unique(y_true)\n",
        "    for c in classes:\n",
        "        for i in range(len(y_true)):\n",
        "            if y_true[i] == c and y_pred[i] == c:\n",
        "                tp += 1\n",
        "            elif y_true[i] != c and y_pred[i] == c:\n",
        "                fp += 1\n",
        "            elif y_true[i] == c and y_pred[i] != c:\n",
        "                fn += 1\n",
        "    p = 0 if (tp + fp) == 0 else tp / (tp + fp)\n",
        "    r = 0 if (tp + fn) == 0 else tp / (tp + fn)\n",
        "    return 0 if (p + r) == 0 else 2 * p * r / (p + r)\n",
        "\n",
        "def macro_f1(y_true, y_pred):\n",
        "    classes = np.unique(y_true)\n",
        "    f1s = []\n",
        "    for c in classes:\n",
        "        tp = fp = fn = 0\n",
        "        for i in range(len(y_true)):\n",
        "            if y_true[i] == c and y_pred[i] == c:\n",
        "                tp += 1\n",
        "            elif y_true[i] != c and y_pred[i] == c:\n",
        "                fp += 1\n",
        "            elif y_true[i] == c and y_pred[i] != c:\n",
        "                fn += 1\n",
        "        p = 0 if (tp + fp) == 0 else tp / (tp + fp)\n",
        "        r = 0 if (tp + fn) == 0 else tp / (tp + fn)\n",
        "        f1s.append(0 if (p + r) == 0 else 2 * p * r / (p + r))\n",
        "    return float(np.mean(f1s))\n",
        "\n",
        "print(f\"Accuracy  (PCA-{top_k}, k={K}): {accuracy(y_test, y_pred):.4f}\")\n",
        "print(f\"Micro-F1  (PCA-{top_k}, k={K}): {micro_f1(y_test, y_pred):.4f}\")\n",
        "print(f\"Macro-F1  (PCA-{top_k}, k={K}): {macro_f1(y_test, y_pred):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP6K_RgmXV72"
      },
      "source": [
        "## Part 3: Tune Hyperparameter (20 points)\n",
        "\n",
        "In this part, you need to do your best to tune the hyperparameters in KNN and PCA to build the best model.\n",
        "\n",
        "You should tune three hyperparameters with the training data provided:\n",
        "\n",
        "- the number of nearest neighbors in KNN\n",
        "- the distance measurement (choose from Euclidean distance, L1 norm distance, and cosine distance)\n",
        "- the number of dimensions kept in PCA\n",
        "\n",
        "\n",
        "**Hint: You can tune these hyperparameters by one randomly generated validation set (like what you have done in previous parts), or you can also use the cross-validation method.**\n",
        "\n",
        "**Hint: To save your time, you can subsample 50% (or even less) of the training data to tune hyperparameters.**\n",
        "\n",
        "**Note: For each hyperparameter, you must try at least 2 different values.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9V2mzzO4qtK",
        "outputId": "b150cfec-1d91-46f9-f4a6-5c32e6fcf337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing PCA=20, K=5, distance=euclidean\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9564\n",
            "\n",
            "Testing PCA=20, K=5, distance=l1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9520\n",
            "\n",
            "Testing PCA=20, K=5, distance=cosine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9504\n",
            "\n",
            "Testing PCA=20, K=10, distance=euclidean\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9541\n",
            "\n",
            "Testing PCA=20, K=10, distance=l1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9505\n",
            "\n",
            "Testing PCA=20, K=10, distance=cosine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9459\n",
            "\n",
            "Testing PCA=50, K=5, distance=euclidean\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9625\n",
            "\n",
            "Testing PCA=50, K=5, distance=l1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9583\n",
            "\n",
            "Testing PCA=50, K=5, distance=cosine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9602\n",
            "\n",
            "Testing PCA=50, K=10, distance=euclidean\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9590\n",
            "\n",
            "Testing PCA=50, K=10, distance=l1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9544\n",
            "\n",
            "Testing PCA=50, K=10, distance=cosine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9566\n",
            "\n",
            "Testing PCA=100, K=5, distance=euclidean\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9596\n",
            "\n",
            "Testing PCA=100, K=5, distance=l1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9508\n",
            "\n",
            "Testing PCA=100, K=5, distance=cosine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9602\n",
            "\n",
            "Testing PCA=100, K=10, distance=euclidean\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9539\n",
            "\n",
            "Testing PCA=100, K=10, distance=l1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9434\n",
            "\n",
            "Testing PCA=100, K=10, distance=cosine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9548\n",
            "\n",
            "\n",
            "================ CLEAN VALIDATION SUMMARY ================\n",
            "\n",
            "Euclidean distance\n",
            "\n",
            "PCA = 20\n",
            "k = 5  → Accuracy = 0.9564\n",
            "k = 10 → Accuracy = 0.9541\n",
            "\n",
            "PCA = 50\n",
            "k = 5  → Accuracy = 0.9625\n",
            "k = 10 → Accuracy = 0.9590\n",
            "\n",
            "PCA = 100\n",
            "k = 5  → Accuracy = 0.9596\n",
            "k = 10 → Accuracy = 0.9539\n",
            "\n",
            "L1 (Manhattan) distance\n",
            "\n",
            "PCA = 20\n",
            "k = 5  → Accuracy = 0.9520\n",
            "k = 10 → Accuracy = 0.9505\n",
            "\n",
            "PCA = 50\n",
            "k = 5  → Accuracy = 0.9583\n",
            "k = 10 → Accuracy = 0.9544\n",
            "\n",
            "PCA = 100\n",
            "k = 5  → Accuracy = 0.9508\n",
            "k = 10 → Accuracy = 0.9434\n",
            "\n",
            "Cosine distance\n",
            "\n",
            "PCA = 20\n",
            "k = 5  → Accuracy = 0.9504\n",
            "k = 10 → Accuracy = 0.9459\n",
            "\n",
            "PCA = 50\n",
            "k = 5  → Accuracy = 0.9602\n",
            "k = 10 → Accuracy = 0.9566\n",
            "\n",
            "PCA = 100\n",
            "k = 5  → Accuracy = 0.9602\n",
            "k = 10 → Accuracy = 0.9548\n",
            "\n",
            "Best Hyperparameters (by Validation Accuracy): {'pca_dim': 50, 'k': 5, 'distance': 'euclidean'}\n",
            "Best Validation Accuracy: 0.9625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def euclidean_distance(X, y):\n",
        "\n",
        "    d = X - y\n",
        "    return np.sqrt(np.sum(d*d, axis=1))\n",
        "\n",
        "def l1_distance(X, y):\n",
        "    return np.sum(np.abs(X - y), axis=1)\n",
        "\n",
        "def cosine_distance(X, y, Xn=None, yn=None):\n",
        "\n",
        "    if Xn is None:\n",
        "        Xn = np.linalg.norm(X, axis=1)\n",
        "    if yn is None:\n",
        "        yn = np.linalg.norm(y)\n",
        "    Xn = np.where(Xn == 0, 1e-12, Xn)\n",
        "    yn = 1e-12 if yn == 0 else yn\n",
        "    sim = (X @ y) / (Xn * yn)\n",
        "    sim = np.clip(sim, -1.0, 1.0)\n",
        "    return 1.0 - sim\n",
        "\n",
        "DIST = {\"euclidean\": euclidean_distance, \"l1\": l1_distance, \"cosine\": cosine_distance}\n",
        "\n",
        "def knn_predict_custom(Xtr, ytr, Xq, k=5, metric='euclidean'):\n",
        "    preds = []\n",
        "    dfunc = DIST[metric]\n",
        "    tr_norm = None\n",
        "    if metric == 'cosine':\n",
        "        tr_norm = np.linalg.norm(Xtr, axis=1)\n",
        "    for i in tqdm(range(len(Xq)), leave=False):\n",
        "        if metric == 'cosine':\n",
        "            y = Xq[i]; yn = np.linalg.norm(y)\n",
        "            d = dfunc(Xtr, y, Xn=tr_norm, yn=yn)\n",
        "        else:\n",
        "            d = dfunc(Xtr, Xq[i])\n",
        "\n",
        "        idx = np.argpartition(d, k)[:k]\n",
        "        labs = ytr[idx]\n",
        "        vals, cnts = np.unique(labs, return_counts=True)\n",
        "        preds.append(vals[np.argmax(cnts)])\n",
        "    return np.array(preds)\n",
        "\n",
        "def pca_fit(X):\n",
        "    mu = X.mean(axis=0)\n",
        "    Xc = X - mu\n",
        "    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
        "    return mu, Vt\n",
        "\n",
        "def pca_project(X, mu, Vt, n_comp):\n",
        "    Xc = X - mu\n",
        "    return Xc @ Vt[:n_comp].T\n",
        "\n",
        "\n",
        "def stratified_train_val_split(X, y, val_ratio=0.5, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    y = np.asarray(y)\n",
        "    classes = np.unique(y)\n",
        "    train_idx = []\n",
        "    val_idx   = []\n",
        "    for c in classes:\n",
        "        idx_c = np.where(y == c)[0]\n",
        "        rng.shuffle(idx_c)\n",
        "        n_val = int(round(val_ratio * len(idx_c)))\n",
        "        val_idx.append(idx_c[:n_val])\n",
        "        train_idx.append(idx_c[n_val:])\n",
        "    train_idx = np.concatenate(train_idx) if len(train_idx) else np.array([], dtype=int)\n",
        "    val_idx   = np.concatenate(val_idx)   if len(val_idx)   else np.array([], dtype=int)\n",
        "    return train_idx, val_idx\n",
        "\n",
        "X_all = features\n",
        "y_all = labels\n",
        "\n",
        "tr_pool_idx, val_idx = stratified_train_val_split(X_all, y_all, val_ratio=0.5, seed=42)\n",
        "\n",
        "sub_ratio = 0.5\n",
        "rng = np.random.default_rng(42)\n",
        "sub_pool = rng.choice(tr_pool_idx, size=int(len(tr_pool_idx) * sub_ratio), replace=False)\n",
        "\n",
        "X_tr = X_all[sub_pool]\n",
        "y_tr = y_all[sub_pool]\n",
        "X_val = X_all[val_idx]\n",
        "y_val = y_all[val_idx]\n",
        "\n",
        "\n",
        "mu_tr, Vt_full = pca_fit(X_tr)\n",
        "\n",
        "pca_dims = [20, 50, 100]\n",
        "k_values = [5, 10]\n",
        "metrics  = ['euclidean', 'l1', 'cosine']\n",
        "\n",
        "best_acc = -1.0\n",
        "best_params = {}\n",
        "summary = {}\n",
        "\n",
        "for dim in pca_dims:\n",
        "    Ztr  = pca_project(X_tr,  mu_tr, Vt_full, dim)\n",
        "    Zval = pca_project(X_val, mu_tr, Vt_full, dim)\n",
        "    for k in k_values:\n",
        "        for m in metrics:\n",
        "            print(f\"Testing PCA={dim}, K={k}, distance={m}\")\n",
        "            y_pred = knn_predict_custom(Ztr, y_tr, Zval, k=k, metric=m)\n",
        "            acc = float(np.mean(y_pred == y_val))\n",
        "            print(f\"Validation Accuracy: {acc:.4f}\\n\")\n",
        "\n",
        "            summary[(m, dim, k)] = acc\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                best_params = {'pca_dim': dim, 'k': k, 'distance': m}\n",
        "\n",
        "\n",
        "def get_acc(metric, dim, k):\n",
        "    v = summary.get((metric, dim, k))\n",
        "    return \"…\" if v is None else f\"{v:.4f}\"\n",
        "\n",
        "print(\"\\n================ CLEAN VALIDATION SUMMARY ================\")\n",
        "\n",
        "print(\"\\nEuclidean distance\")\n",
        "for dim in pca_dims:\n",
        "    print(f\"\\nPCA = {dim}\")\n",
        "    print(f\"k = 5  → Accuracy = {get_acc('euclidean', dim, 5)}\")\n",
        "    print(f\"k = 10 → Accuracy = {get_acc('euclidean', dim, 10)}\")\n",
        "\n",
        "print(\"\\nL1 (Manhattan) distance\")\n",
        "for dim in pca_dims:\n",
        "    print(f\"\\nPCA = {dim}\")\n",
        "    print(f\"k = 5  → Accuracy = {get_acc('l1', dim, 5)}\")\n",
        "    print(f\"k = 10 → Accuracy = {get_acc('l1', dim, 10)}\")\n",
        "\n",
        "print(\"\\nCosine distance\")\n",
        "for dim in pca_dims:\n",
        "    print(f\"\\nPCA = {dim}\")\n",
        "    print(f\"k = 5  → Accuracy = {get_acc('cosine', dim, 5)}\")\n",
        "    print(f\"k = 10 → Accuracy = {get_acc('cosine', dim, 10)}\")\n",
        "\n",
        "print(\"\\nBest Hyperparameters (by Validation Accuracy):\", best_params)\n",
        "print(\"Best Validation Accuracy:\", f\"{best_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfnziIlTXV72"
      },
      "source": [
        "Question: What is your final hyperparameter setting? How do you tune them? What choices have you tried?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5quMH0V4XV72"
      },
      "source": [
        "\n",
        "\n",
        "**Final hyperparameter setting:**\n",
        "\n",
        "* PCA dimensions: **50**\n",
        "* Number of nearest neighbors (K): **5**\n",
        "* Distance metric: **Euclidean distance**\n",
        "\n",
        "**How I tuned them:**\n",
        "I split the provided training data into a training subset and a disjoint validation subset (about 50% each). I then performed a grid search over all three hyperparameters. For PCA, I tried keeping 20, 50, and 100 components; for K I tried 5 and 10 neighbors; and for distance I tested Euclidean, L1 (Manhattan), and Cosine. For each combination, I fit PCA on the training subset, projected both train and validation sets using that mean and component matrix, and then ran KNN on the validation set.\n",
        "\n",
        "**Choices I tried:**\n",
        "\n",
        "* **PCA dims:** {20, 50, 100}\n",
        "* **K:** {5, 10}\n",
        "* **Distance:** {Euclidean, L1, Cosine}\n",
        "\n",
        "After evaluating all combinations, the setting that gave the highest validation accuracy (**0.9625**) was **PCA = 50, K = 5, Euclidean distance**. This is my final hyperparameter choice to carry forward to the test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SRGPS3KXV72"
      },
      "source": [
        "Now, let's test if your best hyperparameter setting really works. We will load a separate testing dataset to test your choice. Let's load the testing data by executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIIr5oAhXV73",
        "outputId": "e53098b1-0174-4232-f08d-3b9725dce63c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "array of testing feature matrix: shape (10000, 784)\n",
            "array of testing labels: shape (10000,)\n"
          ]
        }
      ],
      "source": [
        "test_features = np.loadtxt(\"/content/drive/MyDrive/Colab Notebooks/test.txt\", delimiter=',')\n",
        "test_labels = np.loadtxt(\"/content/drive/MyDrive/Colab Notebooks/test_label.txt\")\n",
        "print('array of testing feature matrix: shape ' + str(np.shape(test_features)))\n",
        "print('array of testing labels: shape ' + str(np.shape(test_labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRsFXTtmXV73"
      },
      "source": [
        "Please apply the KNN model with the best hyperparameter setting you find above to this testing set, and report the Accuracy, and Micro-averaged and Macro-averaged F1 scores of your best model on the testing set.\n",
        "\n",
        "Print out these three metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFYHhgwJXV73",
        "outputId": "4d966eb3-ec6c-4513-8d08-90a2b8811ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:   0.9748\n",
            "Test Micro-F1:   0.9748\n",
            "Test Macro-F1:   0.9747\n"
          ]
        }
      ],
      "source": [
        "best_params = {\n",
        "    'pca_dim': 50,\n",
        "    'k': 5,\n",
        "    'distance': 'euclidean'\n",
        "}\n",
        "\n",
        "\n",
        "def euclidean_distance(X, y): return np.sqrt(np.sum((X - y)**2, axis=1))\n",
        "def l1_distance(X, y): return np.sum(np.abs(X - y), axis=1)\n",
        "def cosine_distance(X, y, Xn=None, yn=None):\n",
        "    if Xn is None: Xn = np.linalg.norm(X, axis=1)\n",
        "    if yn is None: yn = np.linalg.norm(y)\n",
        "    Xn = np.where(Xn == 0, 1e-12, Xn)\n",
        "    yn = 1e-12 if yn == 0 else yn\n",
        "    sim = (X @ y) / (Xn * yn)\n",
        "    return 1.0 - np.clip(sim, -1.0, 1.0)\n",
        "DIST = {\"euclidean\": euclidean_distance, \"l1\": l1_distance, \"cosine\": cosine_distance}\n",
        "\n",
        "def knn_predict(Xtr, ytr, Xq, k, metric):\n",
        "    preds, dfunc = [], DIST[metric]\n",
        "    tr_norm = np.linalg.norm(Xtr, axis=1) if metric == 'cosine' else None\n",
        "    for i in range(len(Xq)):\n",
        "        if metric == 'cosine':\n",
        "            y = Xq[i]; yn = np.linalg.norm(y)\n",
        "            d = dfunc(Xtr, y, Xn=tr_norm, yn=yn)\n",
        "        else:\n",
        "            d = dfunc(Xtr, Xq[i])\n",
        "        idx = np.argpartition(d, k)[:k]\n",
        "        labs = ytr[idx]\n",
        "        vals, cnts = np.unique(labs, return_counts=True)\n",
        "        preds.append(vals[np.argmax(cnts)])\n",
        "    return np.array(preds)\n",
        "\n",
        "\n",
        "def pca_fit(X):\n",
        "    mu = X.mean(axis=0); Xc = X - mu\n",
        "    U,S,Vt = np.linalg.svd(Xc, full_matrices=False)\n",
        "    return mu, Vt\n",
        "def pca_project(X, mu, Vt, n): return (X - mu) @ Vt[:n].T\n",
        "\n",
        "\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true).astype(int).ravel()\n",
        "    y_pred = np.asarray(y_pred).astype(int).ravel()\n",
        "    labels = np.unique(np.concatenate([y_true, y_pred]))\n",
        "    lab2idx = {lab:i for i, lab in enumerate(labels)}\n",
        "    n = len(labels)\n",
        "    C = np.zeros((n, n), dtype=int)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        C[lab2idx[t], lab2idx[p]] += 1\n",
        "    return C\n",
        "\n",
        "def scores(C):\n",
        "    tp = np.diag(C); fp = C.sum(0)-tp; fn = C.sum(1)-tp\n",
        "    prec = np.where(tp+fp>0, tp/(tp+fp),0)\n",
        "    rec  = np.where(tp+fn>0, tp/(tp+fn),0)\n",
        "    f1   = np.where(prec+rec>0, 2*prec*rec/(prec+rec),0)\n",
        "    macro = f1.mean()\n",
        "    TP,FP,FN = tp.sum(), fp.sum(), fn.sum()\n",
        "    micro_p = TP/(TP+FP); micro_r = TP/(TP+FN)\n",
        "    micro = 2*micro_p*micro_r/(micro_p+micro_r)\n",
        "    acc = tp.sum()/C.sum()\n",
        "    return acc, micro, macro\n",
        "\n",
        "mu, Vt = pca_fit(features)\n",
        "Ztr  = pca_project(features, mu, Vt, best_params['pca_dim'])\n",
        "Zte  = pca_project(test_features, mu, Vt, best_params['pca_dim'])\n",
        "\n",
        "\n",
        "y_pred = knn_predict(Ztr, labels, Zte, k=best_params['k'], metric=best_params['distance'])\n",
        "C = confusion_matrix(test_labels, y_pred)\n",
        "acc, micro_f1, macro_f1 = scores(C)\n",
        "\n",
        "print(f\"Test Accuracy:   {acc:.4f}\")\n",
        "print(f\"Test Micro-F1:   {micro_f1:.4f}\")\n",
        "print(f\"Test Macro-F1:   {macro_f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
